{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12478756,"sourceType":"datasetVersion","datasetId":7873533}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageOps\nfrom typing import List, Callable, Optional, Dict\nfrom itertools import cycle\nfrom dataclasses import dataclass\nfrom torch.cuda.amp import autocast, GradScaler\nfrom tqdm import tqdm\nimport shutil\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:36.664274Z","iopub.execute_input":"2025-08-23T13:21:36.664583Z","iopub.status.idle":"2025-08-23T13:21:45.240370Z","shell.execute_reply.started":"2025-08-23T13:21:36.664556Z","shell.execute_reply":"2025-08-23T13:21:45.239493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Bayesian UNet","metadata":{}},{"cell_type":"markdown","source":"## Bayesian UNet Parts","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass EncoderBloc(nn.Module):\n    def __init__(self, in_channels, out_channels, dropout_prob=0.3):\n        super().__init__()\n        self.conv = DoubleConv(in_channels, out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.dropout = nn.Dropout2d(p=dropout_prob)\n\n    def forward(self, x):\n        x_conv = self.conv(x)\n        x_down = self.pool(x_conv)\n        x_down = self.dropout(x_down)\n        return x_down, x_conv\n\nclass DecoderBloc(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x, skip):\n        x = self.up(x)\n        if x.shape[2:] != skip.shape[2:]:\n            x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=True)\n        x = torch.cat([skip, x], dim=1)\n        return self.conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:45.241726Z","iopub.execute_input":"2025-08-23T13:21:45.242170Z","iopub.status.idle":"2025-08-23T13:21:45.252470Z","shell.execute_reply.started":"2025-08-23T13:21:45.242147Z","shell.execute_reply":"2025-08-23T13:21:45.251653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Bayesian UNet Implementation","metadata":{}},{"cell_type":"code","source":"class BayesianUNet(nn.Module):\n    def __init__(self, in_channels, num_classes, dropout_prob):\n        super().__init__()\n\n        # Encoder (Down sampling)\n        self.encoder_bloc_1 = EncoderBloc(in_channels, 64, dropout_prob)\n        self.encoder_bloc_2 = EncoderBloc(64, 128, dropout_prob)\n        self.encoder_bloc_3 = EncoderBloc(128, 256, dropout_prob)\n        self.encoder_bloc_4 = EncoderBloc(256, 512, dropout_prob)\n\n        # Bottleneck\n        self.bottle_neck = DoubleConv(512, 1024)\n\n        # Decoder (Up sampling)\n        self.decoder_bloc_1 = DecoderBloc(1024, 512)\n        self.decoder_bloc_2 = DecoderBloc(512, 256)\n        self.decoder_bloc_3 = DecoderBloc(256, 128)\n        self.decoder_bloc_4 = DecoderBloc(128, 64)\n\n        # Final 1x1 conv\n        self.out = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        # Encoder\n        x2, x1 = self.encoder_bloc_1(x)\n        x3, x2 = self.encoder_bloc_2(x2)\n        x4, x3 = self.encoder_bloc_3(x3)\n        x5, x4 = self.encoder_bloc_4(x4)\n\n        # Bottleneck\n\n        bn = self.bottle_neck(x5)\n\n        # Decoder\n        u1 = self.decoder_bloc_1(bn, x4)\n        u2 = self.decoder_bloc_2(u1, x3)\n        u3 = self.decoder_bloc_3(u2, x2)\n        u4 = self.decoder_bloc_4(u3, x1)\n\n        # Output\n        return self.out(u4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:45.253745Z","iopub.execute_input":"2025-08-23T13:21:45.254033Z","iopub.status.idle":"2025-08-23T13:21:45.272311Z","shell.execute_reply.started":"2025-08-23T13:21:45.254003Z","shell.execute_reply":"2025-08-23T13:21:45.271345Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing Bayesian UNet","metadata":{}},{"cell_type":"code","source":"model = BayesianUNet(3, 5, 0.5)\nx = torch.randn(1, 3, 256, 256)\npred = model(x)\nprint(pred.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:45.274191Z","iopub.execute_input":"2025-08-23T13:21:45.275091Z","iopub.status.idle":"2025-08-23T13:21:46.659222Z","shell.execute_reply.started":"2025-08-23T13:21:45.275057Z","shell.execute_reply":"2025-08-23T13:21:46.658325Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"def add_gaussian_noise(\n    tensor: torch.Tensor,\n    mean: float = 0.0,\n    std: float = 1.0\n) -> torch.Tensor:\n    noise = torch.randn_like(tensor) * std + mean\n    return (tensor + noise).clamp(0.0, 1.0)\n\n\ndef apply_geometric(x, aug_dict, flip_axis, rot_axis0, rot_axis1):\n    if aug_dict[\"flip\"]:\n        x = torch.flip(x, [flip_axis])\n    if aug_dict[\"rot\"]:\n        x = torch.rot90(x, aug_dict[\"rot\"], dims=(rot_axis0,rot_axis1))\n    return x\n\ndef apply_photometric(x, aug_dict):\n    if aug_dict[\"jitter\"] > 0:\n        jitter_tf = T.ColorJitter(\n            brightness=aug_dict[\"jitter\"],\n            contrast=aug_dict[\"jitter\"],\n            saturation=aug_dict[\"jitter\"],\n            hue=aug_dict[\"jitter\"]\n        )\n        x = jitter_tf(x)\n    if aug_dict[\"blur\"]   > 1:\n        blur_tf = T.GaussianBlur(\n            kernel_size=(aug_dict[\"blur\"], aug_dict[\"blur\"]),\n            sigma=(0.1, float(aug_dict[\"blur\"]))\n        )\n\n        x = blur_tf(x)\n    x = add_gaussian_noise(x, aug_dict[\"noise_mean\"], aug_dict[\"noise_std\"])\n    return x\n\ndef augment_image(\n    x: torch.Tensor\n) -> (torch.Tensor, dict):\n\n    flip = bool(random.randint(0, 1))\n    rot = random.randint(0, 3)\n\n    aug_geometric_dict = {\n        \"flip\": flip,\n        \"rot\": rot\n    }\n\n    aug_photometric_dict = {\n        \"jitter\": 0.3,\n        \"blur\": 3,\n        \"noise_mean\": 0.0,\n        \"noise_std\": 0.1\n    }\n\n    x_aug = apply_geometric(x, aug_geometric_dict, flip_axis = 2, rot_axis0 = 1, rot_axis1 = 2)\n    x_aug = apply_photometric(x_aug, aug_photometric_dict)\n\n    return x_aug, aug_geometric_dict\n\ndef augment_mask(\n    x: torch.tensor,\n    aug_dict: dict\n):\n    x_aug = apply_geometric(x, aug_dict, flip_axis=1, rot_axis0=0, rot_axis1=1)\n\n    return x_aug\n\ndef reverse_augmentations(\n    x: torch.Tensor,\n    aug_dict: dict,\n    flip_axis: int = 1,\n    rot_axis0: int = 0,\n    rot_axis1: int = 1\n):\n    # 1) undo rotation\n    k = aug_dict[\"rot\"]\n    if k:\n        inv_k = (4 - k) % 4\n        x = torch.rot90(x, k=inv_k, dims=(rot_axis0, rot_axis1))\n\n    # 2) undo flip\n    if aug_dict[\"flip\"]:\n        x = torch.flip(x, dims=[flip_axis])\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:46.660264Z","iopub.execute_input":"2025-08-23T13:21:46.660594Z","iopub.status.idle":"2025-08-23T13:21:46.672712Z","shell.execute_reply.started":"2025-08-23T13:21:46.660572Z","shell.execute_reply":"2025-08-23T13:21:46.671858Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport random\nfrom PIL import Image, ImageOps\nimport numpy as np\n\nClasses = {\n    (51, 221, 255): 0,  # ICM\n    (250, 50, 83): 1,   # TE\n    (61, 245, 61): 2,   # ZP\n    (255, 245, 61): 3,  # BL\n    (0, 0, 0): 4,       # background\n}\n\nTARGET_SIZE = (256, 256)  # (W, H)\n\n\n# Label Encoding\ndef mask_encoding(arr):\n    h, w, _ = arr.shape\n    class_mask = np.zeros((h, w), dtype=np.uint8)\n    for rgb, idx in Classes.items():\n        class_mask[np.all(arr == rgb, axis=-1)] = idx\n    return class_mask\n\n\nclass BlastocystDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, seed=None, augment=False):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.image_filenames = sorted(os.listdir(image_dir))\n        self.seed = seed\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.image_filenames)\n\n    def __getitem__(self, idx):\n        img_name = self.image_filenames[idx]\n        img_path = os.path.join(self.image_dir, img_name)\n\n        core = os.path.splitext(img_name)[0]\n        mask_path = os.path.join(self.mask_dir, core + \".png\")\n\n\n        img = Image.open(img_path).convert(\"RGB\")\n        img = ImageOps.pad(img, TARGET_SIZE, method=Image.BILINEAR, color=(0, 0, 0))\n        img = np.array(img, np.float32) / 255.0\n        img = torch.from_numpy(img).permute(2, 0, 1)\n\n        mask_rgb = Image.open(mask_path).convert(\"RGB\")\n        mask_rgb = ImageOps.pad(mask_rgb, TARGET_SIZE, method=Image.NEAREST, color=(0, 0, 0))\n        mask_arr = np.array(mask_rgb)\n        mask = mask_encoding(mask_arr)  # [H,W] uint8\n        mask = torch.from_numpy(mask).long()\n\n        if self.augment:\n            img, aug_dict = augment_image(img)\n            mask = augment_mask(mask, aug_dict)\n\n        return img, mask, img_name\n\nclass UnlabeledBlastocystDataset(Dataset):\n    def __init__(self, image_dir):\n        self.image_dir = image_dir\n        self.image_filenames = sorted(os.listdir(image_dir))\n\n    def __len__(self):\n        return len(self.image_filenames)\n\n    def __getitem__(self, idx):\n        img_name = self.image_filenames[idx]\n        img_path = os.path.join(self.image_dir, img_name)\n\n        img = Image.open(img_path).convert(\"RGB\")\n        img = ImageOps.pad(img, TARGET_SIZE, method=Image.BILINEAR, color=(0, 0, 0))\n        img = np.array(img, np.float32) / 255.0\n        img = torch.from_numpy(img).permute(2, 0, 1)\n\n        return img, img_name\n\n\n\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2 ** 32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\n\ndef get_loaders_active(\n        labeled_img_dir,\n        labeled_mask_dir,\n        unlabeled_img_dir,\n        test_img_dir,\n        test_mask_dir,\n        batch_size,\n        seed=None,\n        augment=False,\n        generator=None,\n        num_workers=4,\n        pin_memory=True,\n):\n    # 1. Labeled Dataset (with masks)\n    labeled_ds = BlastocystDataset(\n        image_dir=labeled_img_dir,\n        mask_dir=labeled_mask_dir,\n        seed=seed,\n        augment=augment\n    )\n\n    # 2. Unlabeled Dataset (images only)\n    unlabeled_ds = UnlabeledBlastocystDataset(\n        image_dir=unlabeled_img_dir\n    )\n\n    # 3. Test Dataset (with masks)\n    test_ds = BlastocystDataset(\n        image_dir=test_img_dir,\n        mask_dir=test_mask_dir,\n        seed=seed,\n        augment=False\n    )\n\n    # Create loaders\n    labeled_loader = DataLoader(\n        labeled_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        generator=generator,\n        worker_init_fn=seed_worker,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        drop_last=True  # Helps with batch normalization\n    )\n\n    unlabeled_loader = DataLoader(\n        unlabeled_ds,\n        batch_size=batch_size,\n        shuffle=False,  # Important for sample tracking\n        worker_init_fn=seed_worker,\n        num_workers=num_workers,\n        pin_memory=pin_memory\n    )\n\n    test_loader = DataLoader(\n        test_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        worker_init_fn=seed_worker,\n        num_workers=num_workers,\n        pin_memory=pin_memory\n    )\n\n    return labeled_loader, unlabeled_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:46.673508Z","iopub.execute_input":"2025-08-23T13:21:46.673709Z","iopub.status.idle":"2025-08-23T13:21:46.690648Z","shell.execute_reply.started":"2025-08-23T13:21:46.673693Z","shell.execute_reply":"2025-08-23T13:21:46.689900Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing Image and Mask after augmentation ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\n\n# --- build a discrete colormap directly from your Classes dict ---\nsorted_classes = sorted(Classes.items(), key=lambda x: x[1])  # sort by class ID\ncolors = [np.array(rgb)/255.0 for rgb, _ in sorted_classes]\ncmap = ListedColormap(colors)\nnorm = BoundaryNorm(boundaries=np.arange(-0.5, len(colors)+0.5, 1), ncolors=len(colors))\n\n# --- create dataset (set augment=True if you want augmentations applied) ---\nlabeled_img_dir  = \"/kaggle/input/dataset/images\"\nlabeled_mask_dir = \"/kaggle/input/dataset/masks\"\n\nds = BlastocystDataset(\n    image_dir=labeled_img_dir,\n    mask_dir=labeled_mask_dir,\n    augment=True\n)\n\n# --- get one sample ---\nimg, mask, name = ds[0]   # tensors\nprint(\"Sample:\", name, \"| Image:\", tuple(img.shape), \"| Mask:\", tuple(mask.shape))\n\n# --- convert to numpy for plotting ---\nimg_np  = img.permute(1, 2, 0).cpu().numpy()\nmask_np = mask.cpu().numpy()\n\n# --- plot ---\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.imshow(img_np)\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(mask_np, cmap=cmap, norm=norm, interpolation=\"nearest\")\nplt.title(\"Mask\")\nplt.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:46.691466Z","iopub.execute_input":"2025-08-23T13:21:46.691711Z","iopub.status.idle":"2025-08-23T13:21:47.195870Z","shell.execute_reply.started":"2025-08-23T13:21:46.691693Z","shell.execute_reply":"2025-08-23T13:21:47.194969Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TAAL Core","metadata":{}},{"cell_type":"markdown","source":"## Jensen–Shannon Divergence","metadata":{}},{"cell_type":"code","source":"def tensor_entropy(probs: torch.Tensor, dim: int, eps: float=1e-8) -> torch.Tensor:\n    return -torch.sum(probs * torch.log(probs + eps), dim=dim)\n\ndef entropy_of_average_batch(\n    prob_maps: torch.Tensor\n) -> torch.Tensor:\n    # prob_maps: [K, B, C, H, W]\n    M = prob_maps.mean(dim=0)         # [B, C, H, W]\n    return tensor_entropy(M, dim=1)          # [B, H, W]\n\ndef average_entropy_batch(\n    prob_maps: torch.Tensor\n) -> torch.Tensor:\n    # prob_maps: [K, B, C, H, W]\n    H_each = tensor_entropy(prob_maps, dim=2)  # sum over C → [K, B, H, W]\n    return H_each.mean(dim=0)           # average over K → [B, H, W]\n\ndef JSD_batch(\n    logits_list: List[torch.Tensor],\n    alpha: float = 0.5\n) -> torch.Tensor:\n    \"\"\"\n    logits_list: list of K tensors, each [B, C, H, W]\n    returns: [B] JSD scalar per image in the batch\n    \"\"\"\n    # 1) Stack into [K, B, C, H, W]\n    prob_maps = torch.stack([\n        F.softmax(logits, dim=1)  # softmax over C\n        for logits in logits_list\n    ], dim=0)\n\n    # 2) Compute entropies [B, H, W]\n    H_M   = entropy_of_average_batch(prob_maps)\n    H_avg = average_entropy_batch   (prob_maps)\n\n    # 3) JSD map [B, H, W]\n    jsd_map = alpha * H_M - (1.0 - alpha) * H_avg\n\n    # 4) Reduce spatially to get one scalar per batch element\n    return jsd_map.mean(dim=[1,2])   # → [B]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.196775Z","iopub.execute_input":"2025-08-23T13:21:47.196989Z","iopub.status.idle":"2025-08-23T13:21:47.204888Z","shell.execute_reply.started":"2025-08-23T13:21:47.196971Z","shell.execute_reply":"2025-08-23T13:21:47.203766Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Augment Predict Reverse","metadata":{}},{"cell_type":"code","source":"def augment_predict_reverse(\n    model: torch.nn.Module,\n    images: torch.Tensor,        # [B, C_in, H, W] (can be on CPU or GPU)\n    K: int = 3,\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    for_training: bool = True     # True → train consistency (grads ON), False → eval/AL scoring (grads OFF)\n) -> torch.Tensor:\n    B, C_in, H, W = images.shape\n    model = model.to(device)\n\n    # TAAL behavior:\n    #  - training consistency: train mode, gradients enabled\n    #  - AL/TTA scoring: eval mode, no gradients\n    model.train() if for_training else model.eval()\n\n    all_rev_logits = []\n    ctx = torch.set_grad_enabled(for_training)\n    with ctx:\n        for _ in range(K):\n            batch_aug, batch_params = [], []\n\n            # Do augmentations on CPU (safer for ColorJitter/Blur), then move once to device\n            for img in images:\n                img_cpu = img.detach().to(\"cpu\")                 # ensure CPU for torchvision augs\n                img_aug, params = augment_image(img_cpu)         # your function\n                batch_aug.append(img_aug)\n                batch_params.append(params)\n\n            batch_aug = torch.stack(batch_aug, dim=0).to(device, non_blocking=True)  # [B,C_in,H,W]\n            logits = model(batch_aug)                                                # [B,C_out,H,W]\n\n            # reverse per-sample geometry on logits\n            rev_logits = []\n            for b in range(B):\n                rev = reverse_augmentations(\n                    logits[b],\n                    batch_params[b],\n                    flip_axis=2,   # W in CHW\n                    rot_axis0=1,   # H\n                    rot_axis1=2    # W\n                )  # [C_out,H,W]\n                rev_logits.append(rev)\n            rev_logits = torch.stack(rev_logits, dim=0)  # [B,C_out,H,W]\n            all_rev_logits.append(rev_logits)\n\n    # stack & permute → [B,K,C_out,H,W]\n    all_rev_logits = torch.stack(all_rev_logits, dim=0)             # [K,B,C_out,H,W]\n    all_rev_logits = all_rev_logits.permute(1,0,2,3,4).contiguous() # [B,K,C_out,H,W]\n    return all_rev_logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.206095Z","iopub.execute_input":"2025-08-23T13:21:47.206393Z","iopub.status.idle":"2025-08-23T13:21:47.296971Z","shell.execute_reply.started":"2025-08-23T13:21:47.206362Z","shell.execute_reply":"2025-08-23T13:21:47.296364Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## JSD Consistency Loss","metadata":{}},{"cell_type":"code","source":"def jsd_consistency_batch(\n    model: torch.nn.Module,\n    imgs_U: torch.Tensor,   # [B,C,H,W]\n    K: int = 3,\n    alpha: float = 0.5,\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n) -> torch.Tensor:\n    \"\"\"\n    Train-time JSD consistency loss (scalar).\n    Uses augment_predict_reverse with gradients ON and model.train().\n    \"\"\"\n    # Keep inputs on CPU to avoid GPU->CPU copies inside augment_predict_reverse\n    if imgs_U.is_cuda:\n        imgs_U = imgs_U.detach().cpu()\n\n    logits_tta = augment_predict_reverse(\n        model, imgs_U, K=K, device=device, for_training=True\n    )  # [B,K,C,H,W]\n\n    logits_list = [logits_tta[:, k] for k in range(K)]  # K × [B,C,H,W]\n    loss_per_img = JSD_batch(logits_list, alpha=alpha)  # [B]\n    return loss_per_img.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.299649Z","iopub.execute_input":"2025-08-23T13:21:47.299947Z","iopub.status.idle":"2025-08-23T13:21:47.314049Z","shell.execute_reply.started":"2025-08-23T13:21:47.299917Z","shell.execute_reply":"2025-08-23T13:21:47.313251Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## JSD Score TTA ","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef jsd_score_tta(\n    model: torch.nn.Module,\n    loader,                      # DataLoader (unlabeled_loader)\n    K: int = 3,\n    alpha: float = 0.5,\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n) -> dict:\n    \"\"\"\n    TAAL acquisition scoring (eval mode, no grad).\n    Accepts a DataLoader that yields (imgs, names).\n    Returns: dict {filename: score}\n    \"\"\"\n    model.eval()\n    score_dict = {}\n\n    for imgs, names in loader:         # imgs [B,C,H,W], names list of strings\n        if imgs.is_cuda:\n            imgs = imgs.detach().cpu()\n\n        logits_tta = augment_predict_reverse(\n            model, imgs, K=K, device=device, for_training=False\n        )  # [B,K,C,H,W]\n\n        logits_list = [logits_tta[:, k] for k in range(K)]  # K × [B,C,H,W]\n        scores = JSD_batch(logits_list, alpha=alpha)        # [B]\n\n        for n, s in zip(names, scores.tolist()):\n            score_dict[n] = s\n\n    return score_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.315012Z","iopub.execute_input":"2025-08-23T13:21:47.315345Z","iopub.status.idle":"2025-08-23T13:21:47.329526Z","shell.execute_reply.started":"2025-08-23T13:21:47.315317Z","shell.execute_reply":"2025-08-23T13:21:47.328593Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Core","metadata":{}},{"cell_type":"markdown","source":"## Loss","metadata":{}},{"cell_type":"code","source":"class TverskyLossNoBG(nn.Module):\n    def __init__(self, alpha, beta, smooth=1e-6, bg_idx=4):\n        super().__init__()\n        self.alpha, self.beta = alpha, beta\n        self.smooth = smooth\n        self.bg_idx = bg_idx\n\n    def forward(self, logits, target):\n        B,C,H,W = logits.shape\n        probs   = F.softmax(logits, dim=1)\n        oh      = F.one_hot(target.clamp(0,C-1), C).permute(0,3,1,2).float()\n        dims    = (0,2,3)\n        TP = (probs * oh).sum(dims)\n        FP = (probs * (1 - oh)).sum(dims)\n        FN = ((1 - probs) * oh).sum(dims)\n        # exclude background\n        mask = torch.ones(C, dtype=torch.bool, device=logits.device)\n        mask[self.bg_idx] = False\n        TP,FP,FN = TP[mask], FP[mask], FN[mask]\n        TI = (TP + self.smooth) / (TP + self.alpha*FP + self.beta*FN + self.smooth)\n        return (1 - TI).mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.330482Z","iopub.execute_input":"2025-08-23T13:21:47.330708Z","iopub.status.idle":"2025-08-23T13:21:47.338710Z","shell.execute_reply.started":"2025-08-23T13:21:47.330690Z","shell.execute_reply":"2025-08-23T13:21:47.337878Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"def pixel_accuracy(preds: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n    # preds and targets are of shape (N, H, W)\n    correct = (preds == targets).sum() # Shape: ()\n    total   = preds.numel()\n    return correct.float() / total # Shape: ()\n\ndef macro_dice(preds: torch.Tensor,\n               targets: torch.Tensor,\n               num_classes: int,\n               eps: float = 1e-6) -> torch.Tensor:\n    # preds and targets are of shape (N, H, W)\n    # One-hot encode to (N, H, W, C)\n    p_oh = F.one_hot(preds,   num_classes).permute(0,3,1,2).float() # Shape: (N, H, W, C)\n    t_oh = F.one_hot(targets, num_classes).permute(0,3,1,2).float() # Shape: (N, H, W, C)\n\n    # Sum over batch+spatial dims → (C,)\n    dims = (0, 2, 3)\n    inter = (p_oh * t_oh).sum(dims) # Shape: (C,)\n    union = p_oh.sum(dims) + t_oh.sum(dims) # Shape: (C,)\n\n    dice_per_class = (2 * inter + eps) / (union + eps) # Shape: (C,)\n    return dice_per_class.mean() # Shape: ()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.339518Z","iopub.execute_input":"2025-08-23T13:21:47.339864Z","iopub.status.idle":"2025-08-23T13:21:47.353539Z","shell.execute_reply.started":"2025-08-23T13:21:47.339834Z","shell.execute_reply":"2025-08-23T13:21:47.352816Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sigmoid Ramup","metadata":{}},{"cell_type":"code","source":"def sigmoid_rampup(current: float, rampup_length: int, max_value: float = 1.0) -> float:\n    \"\"\"Smoothly ramps a value from 0 to `max_value` using a Gaussian curve.\"\"\"\n    if rampup_length <= 0:\n        return max_value\n    current = np.clip(current, 0.0, rampup_length)\n    phase = 1.0 - current / rampup_length\n    return max_value * np.exp(-5.0 * phase * phase)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.354308Z","iopub.execute_input":"2025-08-23T13:21:47.354704Z","iopub.status.idle":"2025-08-23T13:21:47.365149Z","shell.execute_reply.started":"2025-08-23T13:21:47.354672Z","shell.execute_reply":"2025-08-23T13:21:47.364519Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Eval","metadata":{}},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass SSLConfig:\n    loss: Callable\n    K: int = 3\n    alpha: float = 0.5\n    use: bool = True\n\n\ndef train_one_epoch(\n    labeled_loader,\n    model: nn.Module,\n    optimizer: torch.optim.Optimizer,\n    loss_sup_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n    device: str = \"cuda\",\n    num_classes: int = 5,\n    scaler: Optional[GradScaler] = None,\n    scheduler=None,\n    step_scheduler_on_batch: bool = False,\n    # ---- SSL (optional) ------------------------------------\n    unlabeled_loader=None,                  # pass only if using SSL\n    ssl: Optional[SSLConfig] = None,        # config for the SSL loss\n    ssl_weight: float = 0.0,                # λ (ramp per epoch outside)\n) -> Dict[str, float]:\n    device = torch.device(device)\n    scaler = scaler or GradScaler()\n    model.train()\n\n    use_ssl = (\n        ssl is not None\n        and ssl.use\n        and ssl_weight > 0.0\n        and (unlabeled_loader is not None)\n        and callable(ssl.loss)\n    )\n\n    ul_iter = cycle(unlabeled_loader) if use_ssl else None\n\n    tot_loss = tot_acc = tot_dice = 0.0\n    n_batches = 0\n\n    pbar = tqdm(labeled_loader, desc=\"Train\", leave=False)\n    for imgs_L, masks_L, *_ in pbar:\n        imgs_L  = imgs_L.float().to(device, non_blocking=True)\n        masks_L = masks_L.long().to(device,  non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast():\n            # supervised branch\n            logits_L = model(imgs_L)\n            loss_sup = loss_sup_fn(logits_L, masks_L)\n\n            # optional SSL branch\n            loss_uns = torch.zeros((), device=device)\n            if use_ssl:\n                imgs_U, *_ = next(ul_iter)\n                imgs_U = imgs_U.float().to(device, non_blocking=True)\n                loss_uns = ssl.loss(model, imgs_U, K=ssl.K, alpha=ssl.alpha, device=device)\n\n            loss = loss_sup + (ssl_weight * loss_uns)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        if scheduler and step_scheduler_on_batch:\n            scheduler.step()\n\n        # metrics on the labeled stream\n        with torch.no_grad():\n            preds      = logits_L.argmax(1)\n            batch_acc  = pixel_accuracy(preds, masks_L)\n            batch_dice = macro_dice(preds, masks_L, num_classes)\n\n        n_batches += 1\n        tot_loss  += loss.item()\n        tot_acc   += batch_acc.item()\n        tot_dice  += batch_dice.item()\n\n        pbar.set_postfix({\n            \"sup\":  loss_sup.item(),\n            \"uns\":  loss_uns.item() if use_ssl else 0.0,\n            \"λ\":    ssl_weight if use_ssl else 0.0,\n            \"loss\": tot_loss / n_batches,\n            \"dice\": tot_dice / n_batches,\n            \"lr\":   optimizer.param_groups[0][\"lr\"],\n        })\n    pbar.close()\n\n    if n_batches == 0:\n        raise ValueError(\"Labeled loader is empty – nothing to train on.\")\n\n    # Step epoch-based schedulers here (not ReduceLROnPlateau)\n    if scheduler and not step_scheduler_on_batch and not isinstance(\n        scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau\n    ):\n        scheduler.step()\n\n    return {\n        \"loss\": tot_loss / n_batches,\n        \"acc%\": (tot_acc / n_batches) * 100.0,\n        \"dice\": tot_dice / n_batches,\n    }\n\n\n@torch.no_grad()\ndef evaluate_loader(loader, model, device=\"cuda\", num_classes=5):\n    model.eval()  # inference mode\n    device = torch.device(device)\n\n    tot_acc, tot_dice, n_batches = 0.0, 0.0, 0\n\n    pbar = tqdm(loader, desc=\"Eval\", leave=False)\n    for imgs, masks, *_ in pbar:\n        imgs = imgs.float().to(device, non_blocking=True)\n        masks = masks.long().to(device, non_blocking=True)\n\n        logits = model(imgs)  # (N, C, H, W)\n        preds = logits.argmax(1)  # (N, H, W)\n\n        batch_acc = pixel_accuracy(preds, masks)\n        batch_dice = macro_dice(preds, masks, num_classes)\n\n        # accumulate\n        tot_acc += batch_acc.item()\n        tot_dice += batch_dice.item()\n        n_batches += 1\n\n        pbar.set_postfix({\"acc%\": tot_acc / n_batches,\n                          \"dice\": tot_dice / n_batches})\n    pbar.close()\n\n    if n_batches == 0:\n        raise ValueError(\"Loader is empty – nothing to evaluate.\")\n\n    return tot_acc / n_batches, tot_dice / n_batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.366062Z","iopub.execute_input":"2025-08-23T13:21:47.366751Z","iopub.status.idle":"2025-08-23T13:21:47.384843Z","shell.execute_reply.started":"2025-08-23T13:21:47.366731Z","shell.execute_reply":"2025-08-23T13:21:47.384059Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Active Learning","metadata":{}},{"cell_type":"markdown","source":"## Acquisition Functions","metadata":{}},{"cell_type":"code","source":"def random_score(model, imgs, **kwargs):\n    return torch.rand(imgs.size(0), device=imgs.device) # Shape: (B,)\n\ndef entropy(model, imgs, T=8, num_classes=5):\n    model.train() # Keep dropout ON for stochasticity\n    probs_sum = torch.zeros(\n        imgs.size(0), num_classes, *imgs.shape[2:], device=imgs.device\n    ) # Shape: (B, C, H, W)\n\n    for _ in range(T):\n        with torch.amp.autocast('cuda'):\n            logits = model(imgs) # Shape: (B, C, H, W)\n            probs  = F.softmax(logits, 1) # Shape: (B, C, H, W)\n        probs_sum += probs\n\n    probs_mean = probs_sum / T # Shape: (B, C, H, W)\n    ent = -(probs_mean * probs_mean.log()).sum(dim=1) # Shape: (B, H, W)\n    return ent.sum(dim=(1, 2)) # Shape: (B,)\n\n\ndef BALD(model, imgs, T=8, num_classes=4):\n    model.train()\n    probs_sum = torch.zeros(\n        imgs.size(0), num_classes, *imgs.shape[2:], device=imgs.device\n    ) # Shape: (B, C, H, W)\n    entropies_sum = torch.zeros(\n        imgs.size(0), *imgs.shape[2:], device=imgs.device\n    ) # Shape: (B, H, W)\n\n    for _ in range(T):\n        with torch.no_grad():\n            with torch.amp.autocast('cuda'):\n                logits = model(imgs) # Shape: (B, C, H, W)\n                probs = F.softmax(logits, dim=1) # Shape: (B, C, H, W)\n\n        # Accumulate probabilities for calculating predictive entropy\n        probs_sum += probs\n\n        # Calculate entropy of the current prediction and accumulate it\n        # H[y|x, Θ_t] = -Σ_c (p_c * log(p_c))\n        entropy_t = -(probs * torch.log(probs + 1e-12)).sum(dim=1) # Shape: (B, H, W)\n        entropies_sum += entropy_t\n\n    # 1. Calculate Predictive Entropy: H[y|x]\n    probs_mean = probs_sum / T # Shape: (B, C, H, W)\n    predictive_entropy = -(probs_mean * torch.log(probs_mean + 1e-12)).sum(dim=1) # Shape: (B, H, W)\n\n    # 2. Calculate Expected Entropy: E[H[y|x, Θ]]\n    expected_entropy = entropies_sum / T # Shape: (B, H, W)\n\n    # 3. Compute BALD score for each pixel\n    # I(y; Θ|x) = H[y|x] - E[H[y|x, Θ]]\n    bald_map = predictive_entropy - expected_entropy # Shape: (B, H, W)\n\n    return bald_map.mean(dim=(1, 2)) # Shape: (B,)\n\n\n\ndef committee_kl_divergence(model, imgs, T=8, num_classes=4):\n    B, _, H, W = imgs.shape\n    device     = imgs.device\n\n    # 1) Monte Carlo posterior under dropout\n    model.train()\n    all_probs = torch.zeros(T, B, num_classes, H, W, device=device) # Shape: (T, B, C, H, W)\n    with torch.no_grad(), torch.amp.autocast('cuda'):\n        for i in range(T):\n            logits      = model(imgs) # Shape: (B, C, H, W)\n            all_probs[i] = F.softmax(logits, dim=1) # Shape: (B, C, H, W)\n    posterior = all_probs.mean(dim=0) # Shape: (B, C, H, W)\n\n    # 2) Deterministic “standard” prediction\n    model.eval()   # Turn OFF dropout here\n    with torch.no_grad(), torch.amp.autocast('cuda'):\n        logits        = model(imgs) # Shape: (B, C, H, W)\n        standard_probs = F.softmax(logits, dim=1) # Shape: (B, C, H, W)\n\n    # 3) Compute per-pixel KL(standard || posterior)\n    eps      = 1e-12\n    P        = torch.clamp(standard_probs,   min=eps)\n    Q        = torch.clamp(posterior,        min=eps)\n    kl_map   = P * (P.log() - Q.log()) # Shape: (B, C, H, W)\n    kl_pixel = kl_map.sum(dim=1) # Shape: (B, H, W)\n    kl_score = kl_pixel.mean(dim=(1, 2)) # Shape: (B,)\n\n    return kl_score\n\ndef committee_js_divergence(model, imgs, T=8, num_classes=4):\n    B, _, H, W = imgs.shape\n    device = imgs.device\n\n    # 1) Monte Carlo posterior Q\n    model.train()  # Keep dropout on\n    all_probs = torch.zeros(T, B, num_classes, H, W, device=device) # Shape: (T, B, C, H, W)\n    with torch.no_grad(), torch.amp.autocast('cuda'):\n        for i in range(T):\n            logits = model(imgs) # Shape: (B, C, H, W)\n            all_probs[i] = F.softmax(logits, dim=1) # Shape: (B, C, H, W)\n    Q = all_probs.mean(dim=0) # Shape: (B, C, H, W)\n\n    # 2) Deterministic standard prediction p\n    model.eval()  # Turn dropout off\n    with torch.no_grad(), torch.amp.autocast('cuda'):\n        logits = model(imgs) # Shape: (B, C, H, W)\n        p = F.softmax(logits, dim=1) # Shape: (B, C, H, W)\n\n    # 3) Build mixture M and clamp for numerical stability\n    eps      = 1e-12\n    p = torch.clamp(p, min=eps)\n    Q = torch.clamp(Q, min=eps)\n    M = torch.clamp(0.5 * (p + Q), min=eps)\n\n    # 4) Compute ½ KL(p‖M) + ½ KL(Q‖M) per pixel\n    kl_p_m = p * (p.log() - M.log()) # Shape: (B, C, H, W)\n    kl_q_m = Q * (Q.log() - M.log()) # Shape: (B, C, H, W)\n    js_map   = 0.5 * (kl_p_m + kl_q_m).sum(dim=1) # Shape: (B, H, W)\n    js_score = js_map.mean(dim=(1, 2)) # Shape: (B,)\n\n    return js_score\n\ndef taal_unweighted_score(model, U, device, K=3):\n    return jsd_score_tta(model, U, K=K, alpha=0.5, device=device)  # [B]\n\ndef taal_weighted_score(model, U, device, K=3):\n    return jsd_score_tta(model, U, K=K, alpha=0.75, device=device) # [B]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.385684Z","iopub.execute_input":"2025-08-23T13:21:47.385983Z","iopub.status.idle":"2025-08-23T13:21:47.405725Z","shell.execute_reply.started":"2025-08-23T13:21:47.385951Z","shell.execute_reply":"2025-08-23T13:21:47.404866Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Active Learning Utilis","metadata":{}},{"cell_type":"code","source":"def create_active_learning_pools(\n        BASE_DIR,\n        label_split_ratio=0.1,\n        test_split_ratio=0.2,\n        shuffle=True\n):\n    # Create directories\n    dirs = {\n        'labeled_img': os.path.join(BASE_DIR, \"Labeled_pool\", 'labeled_images'),\n        'labeled_mask': os.path.join(BASE_DIR, \"Labeled_pool\", 'labeled_masks'),\n        'unlabeled_img': os.path.join(BASE_DIR, \"Unlabeled_pool\", 'unlabeled_images'),\n        'unlabeled_mask': os.path.join(BASE_DIR, \"Unlabeled_pool\", 'unlabeled_masks'),\n        'test_img': os.path.join(BASE_DIR, \"Test\", 'test_images'),\n        'test_mask': os.path.join(BASE_DIR, \"Test\", 'test_masks')\n    }\n\n    dirs[\"labeled_img_dir\"] = dirs[\"labeled_img\"]\n    dirs[\"labeled_mask_dir\"] = dirs[\"labeled_mask\"]\n    dirs[\"unlabeled_img_dir\"] = dirs[\"unlabeled_img\"]\n    dirs[\"test_img_dir\"] = dirs[\"test_img\"]\n    dirs[\"test_mask_dir\"] = dirs[\"test_mask\"]\n\n    for path in dirs.values():\n        os.makedirs(path, exist_ok=True)\n\n    # Get image list\n    img_dir = os.path.join(BASE_DIR, 'images')\n    images = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(\"bmp\")])\n\n    if shuffle:\n        random.shuffle(images)\n\n    # Split images\n    n_test = int(len(images) * test_split_ratio)\n    n_labeled = int(len(images) * label_split_ratio)\n\n    test_split = images[:n_test]\n    labeled_split = images[n_test:n_test + n_labeled]\n    unlabeled_split = images[n_test + n_labeled:]\n\n    def copy_files(file_list, img_dest, mask_dest):\n\n        for im in file_list:\n            base_name = os.path.splitext(im)[0]\n\n            # Copy image\n            src_img = os.path.join(img_dir, im)\n            dst_img = os.path.join(img_dest, im)\n            shutil.copy(src_img, dst_img)\n\n            # Copy mask\n            mask_file = f\"{base_name}.png\"\n            src_mask = os.path.join(BASE_DIR, 'masks', mask_file)\n            dst_mask = os.path.join(mask_dest, mask_file)\n\n            if os.path.exists(src_mask):\n                shutil.copy(src_mask, dst_mask)\n            else:\n                print(f\"Warning: Mask not found for {im} - {src_mask}\")\n\n    copy_files(test_split, dirs['test_img'], dirs['test_mask'])\n    copy_files(labeled_split, dirs['labeled_img'], dirs['labeled_mask'])\n    copy_files(unlabeled_split, dirs['unlabeled_img'], dirs['unlabeled_mask'])\n\n    return dirs\n\ndef reset_data(base_dir):\n    # Directories to remove\n    dirs_to_remove = [\n        os.path.join(base_dir, \"Labeled_pool\"),\n        os.path.join(base_dir, \"Unlabeled_pool\"),\n        os.path.join(base_dir, \"Test\")\n    ]\n\n    for dir_path in dirs_to_remove:\n        if os.path.exists(dir_path):\n            shutil.rmtree(dir_path)\n\n\ndef move_images_with_dict(\n        base_dir: str,\n        labeled_dir: str,\n        unlabeled_dir: str,\n        score_dict: dict,\n        num_to_move: int = 2\n):\n    # Sort by descending uncertainty (most uncertain first)\n    sorted_items = sorted(score_dict.items(), key=lambda x: x[1], reverse=True)\n\n    moved = 0\n    for im, score in sorted_items:\n        if moved >= num_to_move:\n            break\n\n        # Clean filename and get base name\n        im_clean = im.strip()\n        base_name = os.path.splitext(im_clean)[0]\n\n        # Image paths\n        src_im = os.path.join(base_dir, unlabeled_dir, \"unlabeled_images\", im_clean)\n        dst_im = os.path.join(base_dir, labeled_dir, \"labeled_images\", im_clean)\n\n        # Mask paths\n        mask_name = base_name + \".png\"\n        src_msk = os.path.join(base_dir, unlabeled_dir, \"unlabeled_masks\", mask_name)\n        dst_msk = os.path.join(base_dir, labeled_dir, \"labeled_masks\", mask_name)\n\n        # Verify image exists\n        if not os.path.exists(src_im):\n            print(f\"[WARN] Image not found: {src_im}\")\n            continue\n\n        # Move image\n        shutil.copy(src_im, dst_im)\n        os.remove(src_im)\n        print(f\"[MOVE] IMAGE {im_clean} (Uncertainty: {score:.4f})\")\n\n        # Move mask if exists\n        if os.path.exists(src_msk):\n            shutil.copy(src_msk, dst_msk)\n            os.remove(src_msk)\n            print(f\"[MOVE]  MASK {mask_name}\")\n        else:\n            print(f\"[WARN] Mask not found: {src_msk}\")\n\n        moved += 1\n\n    print(f\"Moved {moved} most uncertain images from {unlabeled_dir} → {labeled_dir}.\")\n\ndef score_unlabeled_pool(unlabeled_loader, model, score_fn, num_classes=5, device=\"cuda\"):\n    scores, fnames = [], []\n    with torch.no_grad():\n        for imgs, names in tqdm(unlabeled_loader, desc=\"Scoring\", leave=False):\n            imgs = imgs.to(device)\n            s = score_fn(model, imgs, num_classes=num_classes)\n            scores.extend(s.cpu().tolist())\n            fnames.extend(names)\n    return dict(zip(fnames, scores))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.406562Z","iopub.execute_input":"2025-08-23T13:21:47.406830Z","iopub.status.idle":"2025-08-23T13:21:47.423674Z","shell.execute_reply.started":"2025-08-23T13:21:47.406801Z","shell.execute_reply":"2025-08-23T13:21:47.422918Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Active Learning Loop","metadata":{}},{"cell_type":"markdown","source":"# Benchmarking","metadata":{}},{"cell_type":"code","source":"ACQ_FUNCS = {\n    \"random\":          random_score,\n    \"entropy\":         entropy,\n    \"bald\":            BALD,\n    \"kl-divergence\":   committee_kl_divergence,\n    \"js-divergence\":   committee_js_divergence,\n    \"taal-unweighted\": taal_unweighted_score,\n    \"taal\":            taal_weighted_score\n}\n\n\ndef active_learning_loop(\n        BASE_DIR: str,\n        LABEL_SPLIT_RATIO: float = .1,\n        TEST_SPLIT_RATIO: float = .2,\n        augment: bool = False,\n        sample_size: int = 2,\n        acquisition_type: str = \"js-divergence\",\n        mc_runs: int = 8,\n        dropout = 0.3,\n        batch_size: int = 16,\n        lr: float = 1e-3,\n        seed: int | None = None,\n        loop_iterations: int | None = None,  # set None to disable\n        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n        # early-stopping inside each fine-tune\n        patience: int = 15,\n        min_delta: float = 1e-4,\n        # SSL schedule for TAAL\n        ssl_lambda_max: float = 1.0,\n        ssl_ramp_epochs: int = 10,\n):\n    \"\"\"Active learning loop that supports supervised (entropy/KL/JS/etc.) and TAAL SSL.\"\"\"\n    # ─────────────────── housekeeping ────────────────────────\n    reset_data(BASE_DIR)\n\n    g = torch.Generator()\n    if seed is not None:\n        random.seed(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        g.manual_seed(seed)\n\n    dirs = create_active_learning_pools(\n        BASE_DIR, LABEL_SPLIT_RATIO, TEST_SPLIT_RATIO, shuffle=True\n    )\n    acq = acquisition_type.lower()\n    scorer = ACQ_FUNCS[acq]\n    ckpt_dir = os.path.join(BASE_DIR, \"checkpoints\")\n    os.makedirs(ckpt_dir, exist_ok=True)\n\n    # ─────────────────── model built once ────────────────────\n    model = BayesianUNet(in_channels=3, num_classes=5, dropout_prob=dropout).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    iteration = 0\n    log: list[dict] = []\n    total_train = (\n        len(os.listdir(dirs[\"labeled_img\"])) +  # currently labelled\n        len(os.listdir(dirs[\"unlabeled_img\"]))  # plus still un-labelled\n    )\n    train_on_full_data = False\n\n    # TAAL methods use SSL; others are supervised\n    SSL_METHODS = {\"taal\", \"taal-unweighted\"}\n    \n    alpha_map = {\"taal\": 0.75, \"taal-unweighted\": 0.5}\n\n    # ─────────────────── big loop ────────────────────────────\n    while True:\n        if loop_iterations is not None and iteration >= loop_iterations:\n            break\n\n        n_unl = len(os.listdir(dirs[\"unlabeled_img\"]))\n        if n_unl == 0:\n            if train_on_full_data:\n                print(\"Finished Training on the whole dataset\")\n                break\n            else:\n                print(\"Un-labelled pool exhausted\")\n                train_on_full_data = True\n\n        use_ssl = (acq in SSL_METHODS) and (n_unl > 0)\n        iteration += 1\n        print(f\"\\n── Active Learning Iteration: {iteration} | Unlabelled pool size: {n_unl}\")\n\n        # loaders\n        L, U, T = get_loaders_active(\n            dirs[\"labeled_img\"], dirs[\"labeled_mask\"],\n            dirs[\"unlabeled_img\"],\n            dirs[\"test_img\"], dirs[\"test_mask\"],\n            batch_size=batch_size,\n            seed=seed,\n            augment=augment,\n            generator=g,\n            num_workers=4, pin_memory=True\n        )\n\n        # ───── fine-tune with early stopping (no epoch cap) ───\n        best_val, wait, epoch = -float(\"inf\"), 0, 0\n\n        # class weights for CE\n        num_classes = 5\n        class_counts = torch.zeros(num_classes, dtype=torch.float32, device=device)\n        total_pixels = 0\n        for imgs, masks, _ in L:\n            flat = masks.view(-1).to(device)\n            class_counts += torch.bincount(flat, minlength=num_classes).float()\n            total_pixels += flat.numel()\n        class_freqs = class_counts / total_pixels\n        median_freq = torch.median(class_freqs)\n        weights = (median_freq / class_freqs)\n        weights = weights / weights.mean()\n\n        # supervised loss (CE + Tversky)\n        tversky_fn = TverskyLossNoBG(0.3, 0.7, bg_idx=4).to(device)\n        ce_loss = nn.CrossEntropyLoss(weight=weights)\n        def combined_loss(logits, targets):\n            return ce_loss(logits, targets) + tversky_fn(logits, targets)\n\n        # SSL config for TAAL, otherwise None\n        ssl_cfg = None\n        if use_ssl:\n            ssl_cfg = SSLConfig(loss=jsd_consistency_batch,\n                                K=3,\n                                alpha=alpha_map[acq],\n                                use=True)\n\n        while True:\n            epoch += 1\n\n            # ramp λ only for SSL methods\n            if use_ssl:\n                lambda_t = ssl_lambda_max * sigmoid_rampup(epoch - 1, ssl_ramp_epochs)\n            else:\n                lambda_t = 0.0\n\n            # unified train-one-epoch call (SSL on/off based on args)\n            train_one_epoch(\n                labeled_loader=L,\n                model=model,\n                optimizer=optimizer,\n                loss_sup_fn=combined_loss,\n                device=device,\n                num_classes=5,\n                unlabeled_loader=U if use_ssl and lambda_t > 0 else None,\n                ssl=ssl_cfg,\n                ssl_weight=lambda_t,\n            )\n\n            model.eval()\n            with torch.no_grad():\n                _, val_dice = evaluate_loader(T, model, device=device, num_classes=5)\n            model.train()\n            print(f\"    Epoch {epoch:03d} | val Dice {val_dice:.4f}\")\n\n            if val_dice > best_val + min_delta:\n                best_val, wait = val_dice, 0\n                torch.save(model.state_dict(), os.path.join(ckpt_dir, \"best_tmp.pt\"))\n            else:\n                wait += 1\n                if wait >= patience:\n                    print(f\"    Early-stop after {epoch} epochs\")\n                    break\n\n        model.load_state_dict(torch.load(os.path.join(ckpt_dir, \"best_tmp.pt\"), map_location=device))\n\n        # evaluate & log (on your T loader)\n        _, test_dice = evaluate_loader(T, model, device=device, num_classes=5)\n        curr_labeled = len(os.listdir(dirs[\"labeled_img\"]))\n        frac = curr_labeled / total_train\n        log.append({\"round\": iteration, \"fraction\": frac, \"dice_score\": test_dice})\n        print(f\"[Active Learning iteration: {iteration}]\")\n        print(f\"   Validation Dice = {test_dice:.4f}\")\n\n        # acquisition\n        if not train_on_full_data:\n            if use_ssl:  # TAAL: TTA-based scorer\n                score_dict = scorer(model, U, device=device)\n            else:       # supervised baselines (your existing scorer util)\n                score_dict = score_unlabeled_pool(\n                    U, model, scorer, num_classes=5, device=device\n                )\n            move_images_with_dict(\n                BASE_DIR, \"Labeled_pool\", \"Unlabeled_pool\",\n                score_dict, num_to_move=min(sample_size, n_unl)\n            )\n\n    return pd.DataFrame(log)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.425110Z","iopub.execute_input":"2025-08-23T13:21:47.425420Z","iopub.status.idle":"2025-08-23T13:21:47.449368Z","shell.execute_reply.started":"2025-08-23T13:21:47.425392Z","shell.execute_reply":"2025-08-23T13:21:47.448489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n # ← edit this to match your dataset’s folder under /kaggle/input\n DATASET_PATH=\"/kaggle/input/dataset\"   # e.g. /kaggle/input/embryo-images-and-masks\n\n # where you want to store a local copy\n WORKING_DATA=\"/kaggle/working/data\"\n\n # create the directory\n mkdir -p \"$WORKING_DATA\"\n\n # copy images & masks\n cp -r \"$DATASET_PATH/images\" \"$WORKING_DATA/\"\n cp -r \"$DATASET_PATH/masks\"  \"$WORKING_DATA/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:47.450225Z","iopub.execute_input":"2025-08-23T13:21:47.450516Z","iopub.status.idle":"2025-08-23T13:21:52.818699Z","shell.execute_reply.started":"2025-08-23T13:21:47.450486Z","shell.execute_reply":"2025-08-23T13:21:52.818046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acquisition_funcs = [\"taal\"]\n\nfor acq in acquisition_funcs:\n    print(f\"Running acquisition={acq}\")\n    df = active_learning_loop(\n        BASE_DIR=\"/kaggle/working/data\",\n        LABEL_SPLIT_RATIO=0.1,        \n        TEST_SPLIT_RATIO=0.2,\n        augment=True,\n        sample_size=2,                 \n        acquisition_type=acq,      \n        mc_runs=8,\n        dropout=0.3,\n        batch_size=16,                  \n        lr=1e-3,\n        seed=1,\n        loop_iterations=None,             \n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n        # early-stopping inside each fine-tune\n        patience = 15,\n        min_delta  = 1e-4,\n        # SSL schedule for TAAL\n        ssl_lambda_max = 1.0,\n        ssl_ramp_epochs = 10,\n    )\n    df[\"method\"] = acq\n    output_path = f\"/kaggle/working/{acq}_log.csv\"\n    df.to_csv(output_path, index=False)\n    df.to_csv(output_path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:21:52.819537Z","iopub.execute_input":"2025-08-23T13:21:52.820083Z","iopub.status.idle":"2025-08-23T14:11:01.398382Z","shell.execute_reply.started":"2025-08-23T13:21:52.820050Z","shell.execute_reply":"2025-08-23T14:11:01.397365Z"}},"outputs":[],"execution_count":null}]}